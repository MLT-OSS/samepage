import os

import dotenv

dotenv.load_dotenv()

DEFAULTS = {
    'DB_USERNAME': 'root',
    'DB_PASSWORD': '',
    'DB_HOST': 'localhost',
    'DB_PORT': '3306',
    'DB_DATABASE': 'test',
    'SQLALCHEMY_POOL_SIZE': 30,
    'SQLALCHEMY_ECHO': 'False',
    'PGVECTOR_DRIVER': 'psycopg2',
    'PGVECTOR_USER': 'postgres',
    'PGVECTOR_PASSWORD': '',
    'PGVECTOR_HOST': 'localhost',
    'PGVECTOR_PORT': '5432',
    'PGVECTOR_DATABASE': 'pg_vector',
    'REDIS_HOST': 'localhost',
    'REDIS_PORT': '6379',
    'REDIS_DB': '0',
    'REDIS_USE_SSL': 'False',
    'STORAGE_TYPE': 'local',
    'STORAGE_LOCAL_PATH': 'storage',
    'CELERY_BACKEND': 'database',
}


def get_env(key):
    return os.environ.get(key, DEFAULTS.get(key))


def get_bool_env(key):
    return get_env(key).lower() == 'true'



# Redis
REDIS_HOST = get_env('REDIS_HOST')
REDIS_PORT = get_env('REDIS_PORT')
REDIS_USERNAME = get_env('REDIS_USERNAME')
REDIS_PASSWORD = get_env('REDIS_PASSWORD')
REDIS_DB = get_env('REDIS_DB')
REDIS_USE_SSL = get_bool_env('REDIS_USE_SSL')

# Postgresql
PGVECTOR_DRIVER = get_env('PGVECTOR_DRIVER')
PGVECTOR_HOST = get_env('PGVECTOR_HOST')
PGVECTOR_PORT = get_env('PGVECTOR_PORT')
PGVECTOR_DATABASE = get_env('PGVECTOR_DATABASE')
PGVECTOR_USER = get_env('PGVECTOR_USER')
PGVECTOR_PASSWORD = get_env('PGVECTOR_PASSWORD')

# Storage
STORAGE_TYPE = get_env('STORAGE_TYPE')
STORAGE_LOCAL_PATH = get_env('STORAGE_LOCAL_PATH')
S3_ENDPOINT = get_env('S3_ENDPOINT')
S3_BUCKET_NAME = get_env('S3_BUCKET_NAME')
S3_ACCESS_KEY = get_env('S3_ACCESS_KEY')
S3_SECRET_KEY = get_env('S3_SECRET_KEY')
S3_REGION = get_env('S3_REGION')

# MySQL
db_credentials = {
    key: get_env(key) for key in
    ['DB_USERNAME', 'DB_PASSWORD', 'DB_HOST', 'DB_PORT', 'DB_DATABASE']
}

SQLALCHEMY_DATABASE_URI = f"mysql://{db_credentials['DB_USERNAME']}:{db_credentials['DB_PASSWORD']}@{db_credentials['DB_HOST']}:{db_credentials['DB_PORT']}/{db_credentials['DB_DATABASE']}"
SQLALCHEMY_ENGINE_OPTIONS = {'pool_size': int(get_env('SQLALCHEMY_POOL_SIZE'))}

SQLALCHEMY_ECHO = get_bool_env('SQLALCHEMY_ECHO')

# Celery
CELERY_BROKER_URL = get_env('CELERY_BROKER_URL')
CELERY_BACKEND = get_env('CELERY_BACKEND')
CELERY_RESULT_BACKEND = CELERY_BROKER_URL
BROKER_USE_SSL = CELERY_BROKER_URL.startswith('rediss://')

# LLM
OPENAI_API_BASE_BLOCK = get_env('OPENAI_API_BASE_BLOCK')
OPENAI_API_BASE_STREAM = get_env('OPENAI_API_BASE_STREAM')
OPENAI_API_KEY = get_env('OPENAI_API_KEY')
OPENAI_ORGANIZATION_ID = get_env('OPENAI_ORGANIZATION_ID')
OPENAI_CHAT_MODEL_GPT_3_5_4K = get_env('OPENAI_CHAT_MODEL_GPT_3_5_4K')
OPENAI_CHAT_MODEL_GPT_3_5_16K = get_env('OPENAI_CHAT_MODEL_GPT_3_5_16K')
OPENAI_CHAT_MODEL_GPT_4 = get_env('OPENAI_CHAT_MODEL_GPT_4')
SUMMARY_OPENAI_CHAT_MODEL = get_env('SUMMARY_OPENAI_CHAT_MODEL')
OPENAI_API_BASE_CHAT = OPENAI_API_BASE_STREAM

# 文本拆分
EMBEDDING_TEXT_SPLIT_CHUNK_SIZE = int(get_env('EMBEDDING_TEXT_SPLIT_CHUNK_SIZE'))
EMBEDDING_TEXT_SPLIT_CHUNK_OVERLAP_SIZE = int(get_env('EMBEDDING_TEXT_SPLIT_CHUNK_OVERLAP_SIZE'))
EMBEDDING_PDF_TEXT_SPLIT_CHUNK_SIZE = int(get_env('EMBEDDING_PDF_TEXT_SPLIT_CHUNK_SIZE'))
EMBEDDING_PDF_TEXT_SPLIT_CHUNK_OVERLAP_SIZE = int(get_env('EMBEDDING_PDF_TEXT_SPLIT_CHUNK_OVERLAP_SIZE'))
# SUMMARY_TEXT_SPLIT_CHUNK_SIZE = int(get_env('SUMMARY_TEXT_SPLIT_CHUNK_SIZE'))
SUMMARY_TEXT_SPLIT_CHUNK_SIZE = eval(get_env('SUMMARY_TEXT_SPLIT_CHUNK_SIZE')) if not get_env(
    'SUMMARY_TEXT_SPLIT_CHUNK_SIZE').startswith("-") and '-' in get_env('SUMMARY_TEXT_SPLIT_CHUNK_SIZE') else int(
    get_env('SUMMARY_TEXT_SPLIT_CHUNK_SIZE'))
SUMMARY_TEXT_SPLIT_CHUNK_OVERLAP_SIZE = int(get_env('SUMMARY_TEXT_SPLIT_CHUNK_OVERLAP_SIZE'))

DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_SIZE = eval(get_env('DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_SIZE')) if not get_env(
    'DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_SIZE').startswith("-") and '-' in get_env(
    'DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_SIZE') else int(
    get_env('DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_SIZE'))
# DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_SIZE = int(get_env('DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_SIZE'))
DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_OVERLAP_SIZE = int(get_env('DETAILED_SUMMARY_TEXT_SPLIT_CHUNK_OVERLAP_SIZE'))
EMBEDDING_MODEL_NAME = get_env("EMBEDDING_MODEL_NAME")
MODEL_TOKEN_DICT = dict(item.split(":") for item in get_env("OPENAI_CHAT_MODEL").split(";"))
# token限制
SUMMARY_MAX_TOKEN = int(get_env('SUMMARY_MAX_TOKEN'))
DETAILED_SUMMARY_MAX_TOKEN = int(get_env('DETAILED_SUMMARY_MAX_TOKEN'))
SUGGESTED_QUESTIONS_MAX_TOKEN = int(get_env('SUGGESTED_QUESTIONS_MAX_TOKEN'))
QUESTION_ANSWER_MAX_TOKEN = int(get_env('QUESTION_ANSWER_MAX_TOKEN'))
DOCUMENT_CONTENT_TOKEN_LIMIT = int(get_env('DOCUMENT_CONTENT_TOKEN_LIMIT'))
SUMMARY_DOCUMENT_CONTENT_TOKEN_LIMIT = int(get_env('SUMMARY_DOCUMENT_CONTENT_TOKEN_LIMIT'))

# 问题最大长度
QUESTION_MAX_LEN = int(get_env('QUESTION_MAX_LEN'))

# 相似度匹配阈值
MAX_SIMILARITY_SEARCH_SCORE = float(get_env('MAX_SIMILARITY_SEARCH_SCORE'))
MAX_SIMILARITY_SEARCH_COUNT = int(get_env('MAX_SIMILARITY_SEARCH_COUNT'))

# 摘要和问题生成温度
GENERATE_TEMPERATURE = float(get_env('GENERATE_TEMPERATURE'))

# 联网搜索
BING_SEARCH_URL = get_env('BING_SEARCH_URL')
BING_SUBSCRIPTION_KEY = get_env('BING_SUBSCRIPTION_KEY')
WEB_SEARCH_NUM_RESULTS = int(get_env('WEB_SEARCH_NUM_RESULTS'))
